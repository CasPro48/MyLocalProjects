{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c79d4a",
   "metadata": {},
   "source": [
    "# BombiCode LLM Fine-tuning on Google Colab\n",
    "\n",
    "This notebook fine-tunes the Bombina LLM using LoRA on free Colab GPU.\n",
    "\n",
    "**Steps:**\n",
    "1. Upload your project files\n",
    "2. Install dependencies\n",
    "3. Run training\n",
    "4. Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d46859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Mount Google Drive (optional, for saving checkpoints)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory on Drive\n",
    "!mkdir -p /content/drive/MyDrive/bombina_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cc1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get project files\n",
    "# Option A: Clone from GitHub\n",
    "!git clone https://github.com/CasPro48/MyLocalProjects.git\n",
    "%cd MyLocalProjects/BombiCode\n",
    "\n",
    "# Option B: Upload zip file (alternative)\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# !unzip BombiCode_colab.zip -d /content/\n",
    "# %cd /content/BombiCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Install dependencies\n",
    "!pip install transformers peft datasets accelerate torch torchvision torchaudio --quiet\n",
    "\n",
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Run training\n",
    "# The script now auto-detects GPU\n",
    "!python scripts/finetune_cpu.py\n",
    "\n",
    "# Monitor training (run in separate cell if needed)\n",
    "# !tail -f training_progress.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd915814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Download results\n",
    "# Zip the lora directory\n",
    "!zip -r bombina_lora.zip lora/\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('bombina_lora.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0c557",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Free Colab gives T4 GPU (15GB VRAM) - good for 1.5B model\n",
    "- Sessions timeout after 12 hours - save to Drive regularly\n",
    "- If training stops, resume by re-running the training cell\n",
    "- Monitor GPU usage with !nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
